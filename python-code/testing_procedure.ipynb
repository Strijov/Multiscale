{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data File Format\n",
    "\n",
    "The data we received from the company is in a ',' delimited csv file. Each line of the csv file is of the following format:\n",
    "\n",
    "`metricId, hostId, controlPointId, n, firstTime, lastTime, warn, crit, v1:s1:t1, ..., vn:sn:tn`\n",
    "\n",
    "Here:\n",
    "* `metricID`: the id of the sensor.\n",
    "* `hostId`: the id of a host or device. A host contains multiple metrics. We assume different hosts are independent of one anonther.\n",
    "* `controlPointId` - you can ignore for the time.\n",
    "* `n` - number of data points we have for the current metric.\n",
    "* `firstTime, lastTime` - time stamps of first and last data points.\n",
    "* `warn, crit` - values designating two status thresholds, warning and critical.\n",
    "* `vi:si:ti` - ith data point. `vi` is the actual value, `si` is the current status of the metric (OK, warning or critical), `ti` is the unix time stamp."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method to Read Data\n",
    "Following is the python method we have for redaing the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# required packages\n",
    "import numpy as np\n",
    "import linecache\n",
    "\n",
    "'''\n",
    "get_data: method to read certain metrics from the data file.\n",
    "@param: FILE_NAME is the path to the data file\n",
    "@param: line_indices is the list of line numbers (indices) corresponding to metrics to be retrieved\n",
    "@return: data matrix is in the size of [number of instances (n) , number of time series (length of line_indices)]\n",
    "@return: metric_ids, host_ids, header_names \n",
    "'''\n",
    "def get_data(FILE_NAME, line_indices=[14,15]):\n",
    "    # This block processes the header line, if it exits\n",
    "    header = True  # True means the first line of the csv file in the columns 1 to 8 are variable names\n",
    "    if header == True:\n",
    "        a = linecache.getline(FILE, 1)\n",
    "        b = a.split(',')\n",
    "        header_names = b[0:7]\n",
    "        # dictionaries to store metric ids and host ids against the line indices\n",
    "        metric_ids = {}\n",
    "        host_ids = {}\n",
    "        \n",
    "    # empty matrix to store data\n",
    "    data = []\n",
    "    \n",
    "    # line_indices: input the time series correspond to the same device\n",
    "    for line_index in line_indices:\n",
    "        # retrieve  different fields of a line\n",
    "        a = linecache.getline(FILE, line_index) \n",
    "        b = a.split(',')\n",
    "        \n",
    "        # stores the metricID and hostID against line numbers\n",
    "        if header == True:\n",
    "            metric_ids[line_index] = b[0]\n",
    "            host_ids[line_index] = b[1]\n",
    "        # values of the current metric, v1..vn     \n",
    "        V = []                \n",
    "        for i in range(8,len(b)):            \n",
    "            c = b[i]\n",
    "            v, s, t = c.split(\":\") # value:status:time\n",
    "            V.append(float(v))\n",
    "        # append current values to the data matrix\n",
    "        data.append(V)\n",
    "    \n",
    "    # convert data to numpy format to be used later by sk-learn mathods\n",
    "    data = np.array(data)\n",
    "    data = np.transpose(data)\n",
    "    # returned data matrix is in the size of [number of instances (n) , number of time series (length of line_indices)] \n",
    "    # each column contains the sequence of a time series\n",
    "    return (data, metric_ids, host_ids, header_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Protocol\n",
    "We assume that we already converted the multi-variate time series to the training the matrix. For each variable we select a window size which is best for that variable. We use cross-validation to select the window sizes. This window sizes are later used to embed the time series into the training matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# required packages\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "'''\n",
    "train_model_CV: learns parameters with CV on window size and number of trees\n",
    "@param: data matrix obtained from get_data method above\n",
    "@param: number of folds for cross-validations \n",
    "@param: window sizes to chose from\n",
    "@param: number of trees to choose from\n",
    "@param: forecasting horizon\n",
    "\n",
    "@return: selected window size, number of trees and the corresponding MSE\n",
    "'''\n",
    "def train_model_CV(data, n_fold=5, windows = [5, 10, 25, 50, 75, 100, 150],\n",
    "                   n_trees = [500, 1000, 2000, 3000], f_horizon=1):\n",
    "\n",
    "    scores = np.zeros((len(windows), len(n_trees), n_fold))    \n",
    "\n",
    "    for w_ind in range(0, len(windows)):\n",
    "        # obtain the matrix from  the time series data with a given window-size\n",
    "        (w_train, y_wtrain) = windowize(data, windows[w_ind], f_horizon = f_horizon)\n",
    "            \n",
    "        # cross-validation \n",
    "        r,c = w_train.shape\n",
    "        kf = KFold(r, n_folds=n_fold)\n",
    "        for tree_ind in range(0, len(n_trees)):\n",
    "            reg = RandomForestRegressor(n_estimators=n_trees[tree_ind], n_jobs=24)\n",
    "            n = 0\n",
    "            for train_index, val_index in kf:\n",
    "                # getting training and validation data\n",
    "                X_train, X_val = w_train[train_index,:], w_train[val_index,:]\n",
    "                y_train, y_val = y_wtrain[train_index], y_wtrain[val_index]\n",
    "                # train the model and predict the MSE\n",
    "                reg.fit(X_train, y_train)\n",
    "                pred_val = reg.predict(X_val)\n",
    "                scores[w_ind, tree_ind, n] = mean_squared_error(pred_val, y_val)\n",
    "                n += 1\n",
    "    m_scores = np.average(scores, axis=2)\n",
    "    mse = m_scores.min()\n",
    "        \n",
    "    # select best window_size and best n_tree with smallest MSE\n",
    "    (b_w_ind, b_tree_ind) = np.where(m_scores == mse)\n",
    "    window_size, nr_tree = windows[b_w_ind], n_trees[b_tree_ind]\n",
    "\n",
    "    return (window_size, nr_tree, mse)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
