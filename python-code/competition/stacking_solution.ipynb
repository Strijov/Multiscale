{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from RegressionMatrix import regression_matrix\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# from sklearn.decomposition import PCA\n",
    "from LoadAndSaveData import load_time_series\n",
    "from Forecasting import frc_class\n",
    "from Features import generation_models as gnt_class\n",
    "from Features import quadratic_feature_selection as sel_class\n",
    "# from Forecasting.GatingEnsemble import GatingEnsemble\n",
    "# from Forecasting.LSTM import LSTM\n",
    "import my_plots\n",
    "\n",
    "# Experiment data\n",
    "DATASET = 'EnergyWeather'\n",
    "TS_IDX = [0, 1, 2, 4, 5, 6] # We exclude precipitation from the list of time series\n",
    "\n",
    "# Example of partition. You may use all missing_values time series and both orig time series to test you model.\n",
    "# The final quality will be assesed on varying_rates time series, so don't look at them until you are finished\n",
    "TRAIN_FILE_NAMES = ['missing_value_train']\n",
    "TEST_FILE_NAMES = ['missing_value_test']\n",
    "HIDDEN_TEST = ['varying'] #\n",
    "\n",
    "feature_gnt_names = [None, 'univariate_transformation',\n",
    "                       # 'bivariate_transformation', this one has additional argument\n",
    "                       'simple_statistics',\n",
    "                       'haar_transformations',\n",
    "                       'monotone_linear',\n",
    "                       'monotone_polinomial_rate',\n",
    "                       'monotone_sublinear_polinomial_rate',\n",
    "                       'monotone_logarithmic_rate',\n",
    "                       'monotone_slow_convergence',\n",
    "                       'monotone_fast_convergence',\n",
    "                       'monotone_soft_relu',\n",
    "                       'monotone_sigmoid',\n",
    "                       'monotone_soft_max',\n",
    "                       'monotone_hyberbolic_tangent',\n",
    "                       'monotone_softsign',\n",
    "                       'centroids',\n",
    "                       'all']\n",
    "\n",
    "# output and saving parameters\n",
    "VERBOSE = False\n",
    "SAVE_DIR = \"results\"\n",
    "FNAME_PREFIX = \"\"\n",
    "\n",
    "TRAIN_TEST_RATIO = 0.75\n",
    "N_STEPS = 1 # forecast only one requested interval\n",
    "\n",
    "\n",
    "def load_energy_weather_data(load_raw=None, fnames=TRAIN_FILE_NAMES,\n",
    "                             pickled_file='../data/ProcessedData/EnergyWeather_orig_train.pkl'):\n",
    "    \"\"\"Load data from the EnergyWeather dataset \"\"\"\n",
    "    if load_raw is None:\n",
    "        load_raw = not os.path.exists(pickled_file)\n",
    "\n",
    "    load_time_series.load_all_time_series(datasets=[DATASET], load_raw=load_raw, verbose=VERBOSE)\n",
    "    ts_list = []\n",
    "    for name in fnames:\n",
    "        ts_list.extend(\n",
    "            load_time_series.load_all_time_series(datasets=[DATASET], load_raw=False, name_pattern=name,\n",
    "                                                  verbose=False)\n",
    "        )\n",
    "        print(name)\n",
    "        print(ts_list[-1].summarize_ts())\n",
    "\n",
    "    return ts_list\n",
    "\n",
    "\n",
    "def demo_train(ts_struct_list, frc_model=None, fg_mdl=None, fs_mdl=None, verbose=False,\n",
    "               return_model=False, rewrite=True):\n",
    "    \"\"\"\n",
    "    Train and save the model.\n",
    "\n",
    "    :param ts_struct_list: list of namedtuples tsStruct\n",
    "    :param frc_model: forecasting model, instance of CustomModel\n",
    "    :param fg_mdl: feature generation model, instance of FeatureGeneration\n",
    "    :param fs_mdl: feature selection model, instance of FeatureSelection\n",
    "    :param verbose: controls the output\n",
    "    :return: testError, trainError, bias, model\n",
    "    \"\"\"\n",
    "\n",
    "    # Check arguments:\n",
    "    if fg_mdl is None:\n",
    "        fg_mdl = frc_class.IdentityGenerator(name=\"Identity generator\", on=False)\n",
    "\n",
    "    if fs_mdl is None:\n",
    "        fs_mdl = gnt_class.FeatureGeneration()  # IdentityModel(name=\"Identity selector\")\n",
    "\n",
    "    if frc_model is None:\n",
    "        frc_model = frc_class.CustomModel(Lasso, name=\"Lasso\", alpha=0.01)\n",
    "\n",
    "    model = frc_class.PipelineModel(gen_mdl=fg_mdl, sel_mdl=fs_mdl, frc_mdl=frc_model)\n",
    "    results = []\n",
    "    res_text = []\n",
    "\n",
    "    for ts in ts_struct_list:\n",
    "        data = regression_matrix.RegMatrix(ts, x_idx=TS_IDX, y_idx=TS_IDX)\n",
    "\n",
    "        # Create regression matrix\n",
    "        data.create_matrix(nsteps=N_STEPS, norm_flag=True) # this creates data.Y, data.X and some other fields\n",
    "\n",
    "        # Split data for training and testing\n",
    "        data.train_test_split(TRAIN_TEST_RATIO)\n",
    "\n",
    "        # train the model. This returns trained pipeline and its steps\n",
    "        model, frc, gen, sel = model.train_model(data.trainX, data.trainY)\n",
    "\n",
    "        selection_res = \"\\n Feature selection results: problem status {}, selected {} from {} \\\\\\\\ \\n\".\\\n",
    "            format(sel.status, len(sel.selected), sel.n_vars)\n",
    "\n",
    "        frcY, _ = data.forecast(model) # returns forecasted matrix of the same shape as data.Y\n",
    "        # frcY, idx_frc = data.forecast(model, idx_rows=data.idx_test) # this would return forecasts only for data.testY\n",
    "\n",
    "        data.plot_frc(n_frc=5, n_hist=10, folder=SAVE_DIR) #this saves figures into SAVE_DIR\n",
    "\n",
    "        train_mae = data.mae(idx_rows=data.idx_train, idx_original=data.original_index)\n",
    "        train_mape = data.mape(idx_rows=data.idx_train, idx_original=data.original_index)\n",
    "\n",
    "        test_mae = data.mae(idx_rows=data.idx_test, idx_original=data.original_index)\n",
    "        test_mape = data.mape(idx_rows=data.idx_test, idx_original=data.original_index)\n",
    "\n",
    "        index = [ts.data[i].name for i in TS_IDX]\n",
    "        res1 = pd.DataFrame(train_mae, index=index, columns=[(\"MAE\", \"train\")])\n",
    "        res2 = pd.DataFrame(train_mape, index=index, columns=[(\"MAPE\", \"train\")])\n",
    "        res3 = pd.DataFrame(test_mae, index=index, columns=[(\"MAE\", \"test\")])\n",
    "        res4 = pd.DataFrame(test_mape, index=index, columns=[(\"MAPE\", \"test\")])\n",
    "        res = pd.concat([res1, res2, res3, res4], axis=1)\n",
    "\n",
    "        configuration_str = \"\\n Time series {} forecasted with {} + '{}' feature generation model and  \" \\\n",
    "                            \"'{}' feature selection model \\\\\\\\ \\n\".format(ts.name, frc.name, gen.name, sel.name)\n",
    "        if verbose:\n",
    "            print(configuration_str)\n",
    "            print(selection_res)\n",
    "            print(res)\n",
    "\n",
    "        results.append(res)\n",
    "        res_text.append(configuration_str)\n",
    "        res_text.append(selection_res)\n",
    "\n",
    "    saved_mdl_fname = model.save_model(file_name=FNAME_PREFIX, folder=SAVE_DIR) # saving in not an option yet\n",
    "    # model = frc_class.PipelineModel().load_model(file_name=fname)\n",
    "\n",
    "    # write results into a latex file\n",
    "    my_plots.save_to_latex(results, df_names=res_text, folder=SAVE_DIR, rewrite=rewrite)\n",
    "    print(\"Results saved to folder {}\".format(SAVE_DIR))\n",
    "\n",
    "    if return_model:\n",
    "        return model, saved_mdl_fname\n",
    "\n",
    "    return saved_mdl_fname\n",
    "\n",
    "\n",
    "def competition_errors(model, names, y_idx=None):\n",
    "    \"\"\"\n",
    "    Returns MAPE, averaged over a set of multivariate time series, specified by names\n",
    "\n",
    "    :param model: trained forecasting model\n",
    "    :type model: PipelineModel\n",
    "    :param names: (parts of) names of time series in the set\n",
    "    :type names: list\n",
    "    :param y_idx:\n",
    "    :type y_idx:\n",
    "    :return:\n",
    "    :rtype:\n",
    "    \"\"\"\n",
    "\n",
    "    if isinstance(model, str):\n",
    "        model = frc_class.PipelineModel.load_model(model)\n",
    "\n",
    "    mape = []\n",
    "    for name in names:\n",
    "        ts = load_time_series.load_all_time_series(datasets=['EnergyWeather'], load_raw=False, name_pattern=name, verbose=False)[0]\n",
    "\n",
    "        data = regression_matrix.RegMatrix(ts, y_idx=y_idx)\n",
    "        data.create_matrix()\n",
    "        data.forecast(model)\n",
    "\n",
    "        mape.append(data.mape())\n",
    "\n",
    "    return np.mean(mape), np.std(mape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missing_value_train\n",
      "                   N. obs.            Min            Max     T. min  \\\n",
      "Energy               20096  119995.000000  602703.000000 1999-01-01   \n",
      "Max Temperature        981      -9.913000      35.712002 1999-01-01   \n",
      "Min Temperature        977     -16.389000      20.694000 1999-01-01   \n",
      "Precipitation          980       0.000000      32.689484 1999-01-01   \n",
      "Wind                   985       0.869133       8.273607 1999-01-01   \n",
      "Relative Humidity     1003       0.295366       0.997529 1999-01-01   \n",
      "Solar                  971       0.293850      30.174639 1999-01-01   \n",
      "\n",
      "                                T.max        T. delta     Nans %  \n",
      "Energy            2001-12-31 23:00:00 0 days 01:00:00  23.600973  \n",
      "Max Temperature   2001-12-31 00:00:00 1 days 00:00:00  10.492701  \n",
      "Min Temperature   2001-12-31 00:00:00 1 days 00:00:00  10.857664  \n",
      "Precipitation     2001-12-31 00:00:00 1 days 00:00:00  10.583942  \n",
      "Wind              2001-12-31 00:00:00 1 days 00:00:00  10.127737  \n",
      "Relative Humidity 2001-12-31 00:00:00 1 days 00:00:00   8.485401  \n",
      "Solar             2001-12-31 00:00:00 1 days 00:00:00  11.405109  \n"
     ]
    }
   ],
   "source": [
    "# Load and prepare dataset.\n",
    "ts_list = load_energy_weather_data()\n",
    "\n",
    "# feature selection model can be defined in the same way. If you don't use any, just leave as is\n",
    "selector = sel_class.FeatureSelection(on=False) #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test(frc_model, generator):\n",
    "    # train your model:\n",
    "    model = demo_train(ts_list, frc_model=frc_model, fg_mdl=generator, fs_mdl=selector, verbose=VERBOSE)\n",
    "\n",
    "    # evaluate errors on the test set\n",
    "    train_error, train_std = competition_errors(model=model, names=TRAIN_FILE_NAMES, y_idx=TS_IDX)\n",
    "    test_error, test_std = competition_errors(model=model, names=TEST_FILE_NAMES, y_idx=TS_IDX)\n",
    "\n",
    "\n",
    "    print(\"Average MAPE across time series: train = {} with std {}, test = {} with std {}\".\n",
    "          format(train_error, train_std, test_error, test_std))\n",
    "    return (train_error, test_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict multi-out time-series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from Features.generation_models import CentroidDistances\n",
    "from sklearn.linear_model import Ridge\n",
    "import stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "\n",
    "generator = gnt_class.FeatureGeneration('gen', transformations=CentroidDistances())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to folder results\n",
      "Average MAPE across time series: train = 0.628962144877 with std 0.856391866568, test = 1.29834965244 with std 1.95711299234\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6289621448765198, 1.2983496524393559)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(frc_class.CustomModel(RandomForestRegressor, name=\"RF\"),\n",
    "     generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to folder results\n",
      "Average MAPE across time series: train = 0.863023859138 with std 1.24970047772, test = 1.22378545627 with std 1.73604159396\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.86302385913829005, 1.2237854562699795)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(frc_class.CustomModel(stacking.Stacking, name=\"Wildfowl\",\n",
    "                           base_estimators=[(Ridge().fit, lambda clf, X: clf.predict(X))],\n",
    "                           meta_fitter=RandomForestRegressor().fit,\n",
    "                           n_folds=10),\n",
    "     generator)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "nav_menu": {
   "height": "87px",
   "width": "293px"
  },
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
